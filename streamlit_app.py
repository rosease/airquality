# -*- coding: utf-8 -*-
"""[UNTUK DASHBOARD] Copy of Tubes-DM Kelompok 6 Exp, Prep, Model, Eval.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p-BM9SLFpULB5uyKiXSjqzD1K-biLxt6

TUGAS BESAR - DATA MINING
Kelompok 6

Anggota Kelompok:

1. Ria Andara Azzahra 2211103045
2. Fadiana 2211103055
3. Sa' Baniatun Astia 2211103057

# BUSINESS UNDERSTANDING

Metode: Linear Regression
Tujuan: Memprediksi kadar polutan CO(GT), NO2(GT) dan C6H6(GT) Berdasarkan:
*   Sensor : PT08.S1 (CO), PT08.S2 (NMHC), PT08.S3 (NOx), PT08.S4 (NO2), PT08.S5(O3)
*   ‚Å†Faktor cuaca : T (Temperature), RH (Relative Humidity), AH (Absolut Humidity)

Penerapan LR:
*   Prediksi CO(GT) -> karbon monoksida berdasarkan data inputan sensor.

Keterangan kolom:

1. CO (GT) - karbon monoksida -> sumber : kendaraan, pembakaran
2. ‚Å†NMHC (GT) - Non Methane Hydrocarbons -> sumber : bahan bakar, industri
3. ‚Å†C6H6(GT) - Benzena -> sumber : asap kendaraan, industri
4. ‚Å†NOx(GT) - Nitrogen Oksida -> sumber : emisi kendaraan, pembakaran
5. ‚Å†NO2(GT) - Nitrogen Dioksida -> sumber : kendaraan

# DATA UNDERSTANDING

1. Check redudant values
2. Check missing values
3. Check inconsistent values
4. Check outlier
5. Check noisy values
"""

#Import library
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import joblib
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV, RandomizedSearchCV
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer
import warnings
import statsmodels.api as sm
from sklearn.linear_model import RidgeCV
from sklearn.linear_model import Ridge
from sklearn.model_selection import RandomizedSearchCV
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline
warnings.filterwarnings('ignore')

#Membaca data
dt = pd.read_csv("https://raw.githubusercontent.com/rosease/TP1_DataMining/refs/heads/main/AirQualityUCI.csv", delimiter=';')

dt

dt = dt.dropna(axis=1, how='all')
dt

dt.isnull().sum()

dt.info()

jml_duplikat = dt.duplicated().sum()
print(f"Jumlah duplikat: {jml_duplikat}")

#Print jumlah data, feature
print("Dataset Shape:", dt.shape)
print("\nData Types:")
print(dt.dtypes)
print("\nBasic Statistics:")
print(dt.describe())
print("\nClass Distribution:")

dt.dtypes

# Membersihkan data dari nilai '-200', 'NA', dan spasi
replace_values = ['-200', 'NA', '', ' ']

for col in dt.columns:
    dt[col] = dt[col].astype(str).replace(replace_values, pd.NA)

# Konversi kolom Date dan Time ke datetime
# Jika format Time tidak sesuai, bisa disesuaikan
dt['Date'] = pd.to_datetime(dt['Date'], errors='coerce')
dt['Time'] = pd.to_datetime(dt['Time'], format='%H:%M:%S', errors='coerce').dt.time

# Kolom yang ingin dikonversi ke float
float_columns = ['CO(GT)', 'C6H6(GT)', 'T', 'RH', 'AH']

# Menghapus karakter non-numerik dan mengonversi ke float
for col in float_columns:
    dt[col] = pd.to_numeric(dt[col].str.replace('[^\d.-]', '', regex=True), errors='coerce')

# Menampilkan tipe data setelah konversi
print(dt.dtypes)

# Menampilkan jumlah nilai null per kolom untuk pengecekan
print(dt.isnull().sum())

# Menampilkan beberapa baris pertama untuk memastikan hasil
print(dt.head())

dt.dtypes

dt.isnull().sum()

# Mengonversi kolom numerik ke float
for col in ['CO(GT)', 'C6H6(GT)', 'T', 'RH', 'AH']:
    dt[col] = pd.to_numeric(dt[col], errors='coerce')

# Mengisi NaN dengan mean (bisa diganti median, mode, atau nilai tertentu)
for col in ['CO(GT)', 'C6H6(GT)', 'T', 'RH', 'AH']:
    dt[col].fillna(dt[col].mean(), inplace=True)

dt.isnull().sum()

dt_backup = dt.copy()

# Jika Date dan Time menjadi NaN, kembalikan ke object
dt['Date'] = dt_backup['Date'].astype(str)
dt['Time'] = dt_backup['Time'].astype(str)

dt.isnull().sum()

print(dt_backup['C6H6(GT)'].unique())

import re

# Menampilkan beberapa data untuk inspeksi
print(dt['C6H6(GT)'].apply(repr).head(20))

# Membersihkan data dari karakter non-numerik yang tidak diinginkan
dt['C6H6(GT)'] = dt['C6H6(GT)'].astype(str).apply(lambda x: re.sub(r'[^0-9.-]', '', x))

# Mengonversi ke float dan mengubah yang tidak valid menjadi NaN
dt['C6H6(GT)'] = pd.to_numeric(dt['C6H6(GT)'], errors='coerce')

# Mengisi NaN dengan rata-rata atau cara lain
dt['C6H6(GT)'].fillna(dt['C6H6(GT)'].mean(), inplace=True)

# Cek hasil setelah konversi
print(dt['C6H6(GT)'].head(20))
print(dt['C6H6(GT)'].isnull().sum())  # Mengecek jumlah NaN

# Mengubah kolom 'C6H6(GT)' menjadi string
dt['C6H6(GT)'] = dt['C6H6(GT)'].astype(str)

# Menampilkan hasil
print(dt['C6H6(GT)'].head(20))

dt.isnull().sum()

dt.dtypes

# Mengonversi kolom yang bertipe object ke numerik
cols_to_convert = [
    'PT08.S1(CO)', 'NMHC(GT)', 'C6H6(GT)', 'PT08.S2(NMHC)',
    'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)', 'PT08.S5(O3)'
]

for col in cols_to_convert:
    dt[col] = pd.to_numeric(dt[col], errors='coerce')  # 'coerce' mengubah nilai non-numerik menjadi NaN

# Cek hasil konversi
print(dt.dtypes)
print(dt.head(20))

dt.isnull().sum()

# Membersihkan kolom 'C6H6(GT)' dari karakter yang tidak valid
dt['C6H6(GT)'] = dt['C6H6(GT)'].astype(str).apply(lambda x: ''.join(c for c in x if c.isdigit() or c == '.'))

# Mengonversi ke numerik
dt['C6H6(GT)'] = pd.to_numeric(dt['C6H6(GT)'], errors='coerce')

# Mengisi NaN dengan nilai default, misalnya 114 atau rata-rata
dt['C6H6(GT)'].fillna(114, inplace=True)

# Cek hasil
print(dt['C6H6(GT)'].head(20))

dt.isnull().sum()

dt.dropna(inplace=True)  # Menghapus baris yang mengandung NaN

dt.isnull().sum()

jml_duplikat = dt.duplicated().sum()
print(f"Jumlah duplikat: {jml_duplikat}")

dt.dtypes

# Mengecualikan kolom 'Date' dan 'Time' yang bertipe objek
numeric_cols = dt.select_dtypes(include=['float64', 'int64']).columns

# Menghitung matriks korelasi hanya untuk kolom numerik
plt.figure(figsize=(10, 8))
corr = dt[numeric_cols].corr()  # Hanya menggunakan kolom numerik
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f", square=True)
plt.title('Correlation Matrix')
plt.show()

#Visualisasi nilai outlier
dt.describe()
dt.plot(kind='box',subplots=True,layout=(5,6), sharex=False,figsize = (20,20),
        title='figure 1: Columns Outlier')
plt.show()

# Lihat jumlah NaN per kolom
print(dt.isna().sum())

# --- 3. Tangani Outlier (cap outliers versi aman) ---
def cap_outliers(dt):
    dt_capped = dt.copy()
    # Filter hanya kolom bertipe numerik
    numeric_cols = dt.select_dtypes(include=[np.number]).columns

    for col in numeric_cols:
        Q1 = dt[col].quantile(0.25)
        Q3 = dt[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR

        # Batasi nilai outlier
        dt_capped[col] = np.where(dt[col] < lower, lower,
                           np.where(dt[col] > upper, upper, dt[col]))
    return dt_capped

dt_clean = cap_outliers(dt)
non_numeric_cols = dt.select_dtypes(exclude=[np.number]).columns
print("Kolom non-numerik:", list(non_numeric_cols))

# --- 4. Tampilkan Boxplot Ulang untuk Cek Outlier ---
plt.figure(figsize=(20, 15))
for i, col in enumerate(numeric_cols):
    plt.subplot(int(np.ceil(len(numeric_cols) / 5)), 5, i + 1)
    sns.boxplot(y=dt_clean[col])
    plt.title(col, fontsize=8)
plt.suptitle("Boxplot Setelah Penanganan Outlier (Numerik Saja)", fontsize=16)
plt.tight_layout()
plt.show()

dt_clean.dtypes

print(dt_clean.isna().sum())

jml_duplikat = dt_clean.duplicated().sum()
print(f"Jumlah duplikat: {jml_duplikat}")

dt_clean

dt_clean.isna().sum()

print(dt_clean['Time'].unique())

dt_clean.describe()

dt_clean.isna().sum()

from datetime import time

# Waktu representatif
time_slots = [time(6, 0), time(12, 0), time(17, 0), time(21, 0)]
labels = ['Pagi', 'Siang', 'Sore', 'Malam']

# Deteksi NaT di kolom 'Time'
mask_nat = dt_clean['Time'].isna()
num_missing = mask_nat.sum()

# Bagi secara merata ke 4 waktu
filled_times = np.tile(time_slots, num_missing // 4 + 1)[:num_missing]

# Masukkan nilai waktu ke baris yang kosong
dt_clean.loc[mask_nat, 'Time'] = filled_times

# Konfirmasi hasil
print(dt_clean['Time'].isna().sum())  # Harus 0

dt_clean.isna().sum()

dt_clean.describe()

dt_clean

non_numeric_cols = dt.select_dtypes(exclude=[np.number]).columns
print("Kolom non-numerik:", list(non_numeric_cols))

# --- 4. Tampilkan Boxplot Ulang untuk Cek Outlier ---
plt.figure(figsize=(20, 15))
for i, col in enumerate(numeric_cols):
    plt.subplot(int(np.ceil(len(numeric_cols) / 5)), 5, i + 1)
    sns.boxplot(y=dt_clean[col])
    plt.title(col, fontsize=8)
plt.suptitle("Boxplot Setelah Penanganan Outlier (Numerik Saja)", fontsize=16)
plt.tight_layout()
plt.show()

# Mengecek duplikat berdasarkan seluruh kolom
jml_duplikat = dt_clean.duplicated().sum()
print(f"Jumlah duplikat: {jml_duplikat}")

# Mengasumsikan dt_clean sudah ada
dt_clean = dt_clean.drop_duplicates()

# Menampilkan data yang sudah dibersihkan
print(dt_clean)

# Mengecek duplikat berdasarkan seluruh kolom
jml_duplikat = dt_clean.duplicated().sum()
print(f"Jumlah duplikat: {jml_duplikat}")

# Mengecek kolom yang mengandung -200.0
columns_with_inconsistent_values = []

for col in dt_clean.columns:
    if dt_clean[col].eq(-200.0).any():  # Mengecek apakah ada nilai -200.0 di kolom
        columns_with_inconsistent_values.append(col)

# Menampilkan kolom yang memiliki nilai -200.0
print("Kolom dengan nilai -200.0 (tidak konsisten):")
print(columns_with_inconsistent_values)

# Kolom yang memiliki nilai -200.0 yang perlu diganti
cols_change = ['NMHC(GT)', 'NOx(GT)']

# Mengganti nilai -200.0 dengan median untuk setiap kolom
for col in cols_change:
    # Mengganti nilai -200.0 dengan NaN untuk perhitungan median
    valid_values = dt_clean[col].replace(-200.0, np.nan)

    # Menghitung median hanya jika masih ada nilai yang valid setelah penggantian
    if valid_values.notna().any():  # Mengecek apakah ada nilai selain NaN
        median_value = valid_values.median()  # Menghitung median dari nilai yang valid
        dt_clean[col] = dt_clean[col].replace(-200.0, median_value)  # Ganti -200.0 dengan median
    else:
        print(f"Kolom {col} tidak memiliki data yang valid setelah penggantian -200.0.")

# Menampilkan DataFrame setelah perubahan
print(dt_clean[cols_change].head())  # Menampilkan kolom yang sudah diperbaiki

dt_clean.isna().sum()

# Misalkan dt_clean adalah DataFrame Anda

# Kolom yang akan diperbaiki
col_to_fix = 'NMHC(GT)'

# Menentukan rentang nilai yang realistis untuk NMHC(GT)
min_value = 50.0  # Nilai minimum yang masuk akal
max_value = 150.0  # Nilai maksimum yang masuk akal

# Mengganti nilai -200.0 dengan NaN terlebih dahulu
dt_clean[col_to_fix] = dt_clean[col_to_fix].replace(-200.0, np.nan)

# Membuat nilai acak untuk menggantikan NaN dalam rentang yang ditentukan
np.random.seed(0)  # Set seed untuk reproduktifitas
random_values = np.random.uniform(min_value, max_value, size=dt_clean[col_to_fix].isna().sum())

# Menyisipkan nilai acak pada posisi NaN
dt_clean.loc[dt_clean[col_to_fix].isna(), col_to_fix] = random_values

# Menampilkan hasil
print(dt_clean[col_to_fix].head())  # Menampilkan kolom yang sudah diperbaiki

dt_clean.isna().sum()

# Mengecek duplikat berdasarkan seluruh kolom
jml_duplikat = dt_clean.duplicated().sum()
print(f"Jumlah duplikat: {jml_duplikat}")

dt_clean

non_numeric_cols = dt_clean.select_dtypes(exclude=[np.number]).columns
print("Kolom non-numerik:", list(non_numeric_cols))

# --- 4. Tampilkan Boxplot Ulang untuk Cek Outlier ---
plt.figure(figsize=(20, 15))
for i, col in enumerate(numeric_cols):
    plt.subplot(int(np.ceil(len(numeric_cols) / 5)), 5, i + 1)
    sns.boxplot(y=dt_clean[col])
    plt.title(col, fontsize=8)
plt.suptitle("Boxplot Setelah Penanganan Outlier (Numerik Saja)", fontsize=16)
plt.tight_layout()
plt.show()

# Kolom yang mengandung outlier
cols_with_outliers = ['PT08.S1(CO)', 'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)', 'PT08.S4(NO2)', 'PT08.S5(O3)']

# Fungsi untuk mendeteksi outlier dan menampilkan jumlah outlier
def count_outliers(dt_clean, cols):
    outlier_counts = {}

    for col in cols:
        # Menghitung Q1, Q3 dan IQR
        Q1 = dt_clean[col].quantile(0.25)
        Q3 = dt_clean[col].quantile(0.75)
        IQR = Q3 - Q1

        # Mendefinisikan batas bawah dan batas atas untuk outlier
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        # Menampilkan jumlah outlier di kolom ini
        outliers = ((dt_clean[col] < lower_bound) | (dt_clean[col] > upper_bound))
        outlier_count = outliers.sum()

        outlier_counts[col] = outlier_count

    return outlier_counts

# Menghitung jumlah outlier
outlier_counts = count_outliers(dt_clean, cols_with_outliers)

# Menampilkan jumlah outlier
for col, count in outlier_counts.items():
    print(f"Jumlah outlier di kolom {col}: {count}")

# Menghapus baris yang memiliki outlier berdasarkan IQR
def remove_outliers(dt_clean, cols):
    for col in cols:
        Q1 = dt_clean[col].quantile(0.25)
        Q3 = dt_clean[col].quantile(0.75)
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        # Hapus baris yang memiliki outlier
        dt_clean = dt_clean[(dt_clean[col] >= lower_bound) & (dt_clean[col] <= upper_bound)]

    return dt_clean

# Menghapus outlier
dt_clean_outliers_removed = remove_outliers(dt_clean, cols_with_outliers)

# Menampilkan hasil setelah penghapusan outlier
print(dt_clean_outliers_removed[cols_with_outliers].head())

# Menentukan kolom numerik setelah proses pembersihan
numeric_cols = dt_clean_outliers_removed.select_dtypes(include=[np.number]).columns

# Tampilkan kolom numerik
print("Kolom numerik:", list(numeric_cols))

# --- 4. Tampilkan Boxplot Ulang untuk Cek Outlier ---
plt.figure(figsize=(20, 15))

# Membuat boxplot untuk setiap kolom numerik
for i, col in enumerate(numeric_cols):
    plt.subplot(int(np.ceil(len(numeric_cols) / 5)), 5, i + 1)  # Membuat subplots secara otomatis
    sns.boxplot(y=dt_clean_outliers_removed[col])  # Boxplot berdasarkan data setelah penghapusan outlier
    plt.title(col, fontsize=8)  # Menambahkan judul untuk setiap plot

plt.suptitle("Boxplot Setelah Penanganan Outlier (Numerik Saja)", fontsize=16)  # Judul utama
plt.tight_layout()  # Menyusun layout agar tidak tumpang tindih
plt.show()

# Kolom yang mengandung outlier
cols_outlierss = ['CO(GT)', 'PT08.S1(CO)', 'PT08.S2(NMHC)', 'C6H6(GT)', 'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)', 'PT08.S5(O3)']

# Fungsi untuk mendeteksi outlier dan menampilkan jumlah outlier
def count_outliers(dt_clean_outliers_removed, cols):
    outlier_counts = {}

    for col in cols:
        # Menghitung Q1, Q3 dan IQR
        Q1 = dt_clean_outliers_removed[col].quantile(0.25)
        Q3 = dt_clean_outliers_removed[col].quantile(0.75)
        IQR = Q3 - Q1

        # Mendefinisikan batas bawah dan batas atas untuk outlier
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        # Menampilkan jumlah outlier di kolom ini
        outliers = ((dt_clean_outliers_removed[col] < lower_bound) | (dt_clean_outliers_removed[col] > upper_bound))
        outlier_count = outliers.sum()

        outlier_counts[col] = outlier_count

    return outlier_counts

# Menghitung jumlah outlier
outlier_counts = count_outliers(dt_clean_outliers_removed, cols_with_outliers)

# Menampilkan jumlah outlier
for col, count in outlier_counts.items():
    print(f"Jumlah outlier di kolom {col}: {count}")

def replace_outliers_with_median(data, cols):
    data_filled = data.copy()
    for col in cols:
        Q1 = data_filled[col].quantile(0.25)
        Q3 = data_filled[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        median_value = data_filled[col].median()

        # Ganti nilai outlier dengan median
        data_filled.loc[(data_filled[col] < lower_bound) | (data_filled[col] > upper_bound), col] = median_value

    return data_filled

# Terapkan ke dt_clean dan simpan ke variabel baru
dt_clean_remove_outlier = replace_outliers_with_median(dt_clean, cols_outlierss)

# Tampilkan jumlah data
print(f"\nJumlah data setelah pengisian outlier (dengan median): {len(dt_clean_remove_outlier)} baris")

# Cek jumlah outlier tersisa setelah penggantian
def count_remaining_outliers(data, cols):
    outlier_count = {}
    for col in cols:
        Q1 = data[col].quantile(0.25)
        Q3 = data[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        outliers = data[(data[col] < lower) | (data[col] > upper)]
        outlier_count[col] = len(outliers)
    return outlier_count

outlier_summary = count_remaining_outliers(dt_clean_remove_outlier, cols_outlierss)
print("Sisa outlier setelah penggantian:", outlier_summary)

# Fungsi untuk clipping outlier
def clip_outliers(data, cols):
    for col in cols:
        Q1 = data[col].quantile(0.25)
        Q3 = data[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR

        # Clipping nilai yang lebih kecil dari lower dan lebih besar dari upper
        data[col] = data[col].clip(lower, upper)

    return data

# Terapkan clipping ke dt_clean_remove_outlier untuk menangani sisa outlier
dt_clean_final = clip_outliers(dt_clean_remove_outlier, cols_outlierss)

# Tampilkan boxplot untuk cek apakah clipping berhasil
plt.figure(figsize=(20, 15))

for i, col in enumerate(numeric_cols):
    plt.subplot(int(np.ceil(len(numeric_cols) / 5)), 5, i + 1)
    sns.boxplot(y=dt_clean_final[col])
    plt.title(col, fontsize=8)

plt.suptitle("Boxplot Setelah Cleaning", fontsize=16)
plt.tight_layout()
plt.show()

# 1. Cek Null/Nan
null_counts = dt_clean_final.isnull().sum()
missing_percentage = (null_counts / len(dt_clean_final)) * 100
print(f"Jumlah nilai null/Nan Setelah Cleansing:\n{null_counts}")
print(f"\nPersentase missing values per kolom:\n{missing_percentage}")

# 2. Cek Duplicate
duplicate_counts = dt_clean_final.duplicated().sum()
print(f"Jumlah duplikat: {duplicate_counts}")
dt_clean_clipped = dt_clean_final.drop_duplicates()
print(f"Jumlah data setelah menghapus duplikat: {len(dt_clean_clipped)}")

# 3. Cek Distribusi Data (Normalitas)
plt.figure(figsize=(20, 15))
for i, col in enumerate(numeric_cols):
    plt.subplot(int(np.ceil(len(numeric_cols) / 5)), 5, i + 1)
    sns.histplot(dt_clean_final[col], kde=True, bins=30)
    plt.title(col, fontsize=8)

plt.suptitle("Distribusi Data", fontsize=16)
plt.tight_layout()
plt.show()

# 4. Normalisasi
from sklearn.preprocessing import MinMaxScaler, StandardScaler

scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(dt_clean_final[numeric_cols])
dt_clean_final[numeric_cols] = scaled_data

print("Data setelah normalisasi/standarisasi:\n", dt_clean_final.head())

print(dt_clean_final.dtypes)

dt_clean_final.isna().sum()

print(dt_clean_final.isna().sum())

"""# **MODELING**"""

#SPLIT DATA

# Memisahkan target (X) dan fitur (y)
x = dt_clean_final.drop(['CO(GT)', 'Date', 'Time'], axis=1) #fitur-fitur inputan, mengecualikan date dan time
y = dt_clean_final['CO(GT)'] #target yang ingin diprediksi

# Membagi data menjadi data pelatihan dan pengujian
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

print("X_train shape:", x_train.shape)
print("y_train shape:", y_train.shape)

#Melatih Model
model = LinearRegression(fit_intercept=True, copy_X=True, n_jobs=None, positive=False)
model.fit(x_train, y_train)

# Analisis Regresi Linier
x_train_const = sm.add_constant(x_train)
ols_model = sm.OLS(y_train, x_train_const)
result = ols_model.fit()
print(result.summary())

# Prediksi Model
y_pred = model.predict(x_test)

intercept = model.intercept_ # Mendapatkan nilai intercept dari model
coefficients = model.coef_ # Mendapatkan koefisien untuk setiap fitur

print("Intercept:", intercept)
print("Koefisien:", coefficients)

from sklearn.feature_selection import SelectKBest, f_regression
import pandas as pd

# Feature selection pada data latih
selector = SelectKBest(score_func=f_regression, k='all')
selector.fit(x_train, y_train)

# Melihat skor tiap fitur
feature_scores = pd.DataFrame({
    'Feature': x_train.columns,
    'Score': selector.scores_
}).sort_values(by='Score', ascending=False)

print("Skor fitur berdasarkan SelectKBest:")
print(feature_scores)

selected_features = ['NMHC(GT)', 'C6H6(GT)', 'NOx(GT)', 'NO2(GT)', 'RH', 'T', 'AH']
X_custom = dt_clean_final[selected_features]
y_custom = dt_clean_final['CO(GT)']

# Split
x_train_custom, x_test_custom, y_train_custom, y_test_custom = train_test_split(X_custom, y_custom, test_size=0.2, random_state=42)

# Scaling (opsional tergantung model)
scaler = StandardScaler()
x_train_custom_scaled = scaler.fit_transform(x_train_custom)
x_test_custom_scaled = scaler.transform(x_test_custom)
print("X_train shape:", x_train_custom_scaled.shape)
print("y_train shape:", y_train_custom.shape)

#selected_features = ['NMHC(GT)', 'C6H6(GT)', 'NOx(GT)']

# Gunakan hanya fitur terpilih
x_train_selected = x_train[selected_features]
x_test_selected = x_test[selected_features]

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Inisialisasi dan pelatihan model
model = LinearRegression()
model.fit(x_train_selected, y_train)

# Prediksi
y_pred = model.predict(x_test_selected)

"""# **EVALUATION**"""

# Evaluasi
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error (MSE) Model LR: {mse:.2f}')
print(f'R-Squared (R¬≤) Model LR: {r2:.2f}')

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.xlabel("Actual CO(GT)")
plt.ylabel("Predicted CO(GT)")
plt.title("Actual vs Predicted CO(GT)")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # garis ideal
plt.show()

from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(degree=2, include_bias=False)
x_poly_train = poly.fit_transform(x_train_selected)
x_poly_test = poly.transform(x_test_selected)

model_poly = LinearRegression()
model_poly.fit(x_poly_train, y_train)
y_pred_poly = model_poly.predict(x_poly_test)

print("R2 poly:", r2_score(y_test, y_pred_poly))

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(random_state=42)
rf.fit(x_train_selected, y_train)
y_pred_rf = rf.predict(x_test_selected)

print("MSE RF:", mean_squared_error(y_test, y_pred_rf))
print("R2 RF:", r2_score(y_test, y_pred_rf))

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5]
}

grid = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=3, scoring='r2')
grid.fit(x_train_selected, y_train)

print("Best Params:", grid.best_params_)
print("Best R2:", grid.best_score_)

"""# **OPTIMASI MODEL (CLEANING ULANG)**"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_regression
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score

# Load dataset
dt = pd.read_csv('https://raw.githubusercontent.com/rosease/TP1_DataMining/refs/heads/main/AirQualityUCI.csv', sep=';', decimal=',')

# Drop kolom tidak penting
dt.drop(columns=['Unnamed: 15', 'Unnamed: 16'], inplace=True, errors='ignore')
dt.dropna(how='all', inplace=True)

# Ganti -200 jadi NaN
dt.replace(-200, np.nan, inplace=True)

# Gabungkan dan konversi Date + Time
dt['DateTime'] = pd.to_datetime(dt['Date'] + ' ' + dt['Time'], format='%d/%m/%Y %H.%M.%S', errors='coerce')
dt.drop(columns=['Date', 'Time'], inplace=True)

# Hapus baris yang mengandung NaN
dt_clean = dt.dropna()

# Pisahkan fitur dan target
X = dt_clean.drop(columns=['CO(GT)', 'DateTime'])
y = dt_clean['CO(GT)']

# Feature selection
selector = SelectKBest(score_func=f_regression, k=7)
X = X.loc[:, selector.fit(X, y).get_support()]

# Split data
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardisasi
scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled = scaler.transform(x_test)

"""# **MEMBANDINGKAN DENGAN MODEL LAIN (FINAL EVALUATION)**"""

# Model
models = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(random_state=42),
    "Gradient Boosting": GradientBoostingRegressor(random_state=42),
    "Support Vector Regression": SVR()
}

# Evaluasi
results = {}
for name, model in models.items():
    if name == "Support Vector Regression":
        model.fit(x_train_scaled, y_train)
        y_pred = model.predict(x_test_scaled)
    else:
        model.fit(x_train, y_train)
        y_pred = model.predict(x_test)

    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    results[name] = {"MSE": mse, "R2": r2}

# Output
results_dt = pd.DataFrame(results).T.sort_values(by="R2", ascending=False)
print(results_dt)

# Inisialisasi model
lr = LinearRegression()

# Fit model ke data pelatihan
lr.fit(x_train, y_train)

# Prediksi pada data uji
y_pred = lr.predict(x_test)

# Prediksi pada data uji
y_pred = lr.predict(x_test)  # menggunakan model Linear Regression (lr)

# Visualisasi aktual vs prediksi
plt.figure(figsize=(10,6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.7, color='blue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Garis ideal
plt.xlabel("Nilai Aktual CO (mg/m^3)")
plt.ylabel("Nilai Prediksi CO (mg/m^3)")
plt.title("Perbandingan Nilai Aktual vs Prediksi - Linear Regression")
plt.grid(True)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10,6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.7, color='green')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Nilai Aktual CO (mg/m^3)")
plt.ylabel("Nilai Prediksi CO (mg/m^3)")
plt.title("Perbandingan Nilai Aktual vs Prediksi - Linear Regression")
plt.grid(True)
plt.tight_layout()
plt.show()

"""Dari test ini model terbaik yang diperoleh adalah melalui optimasi model menggunakan Polynomial dengan MSE : 0.064175 dan R2: 0.969171 pada model Regresi Linier

"""

from sklearn.feature_selection import SelectKBest, f_regression

selector = SelectKBest(score_func=f_regression, k=7)
X_new = selector.fit_transform(X, y)

selected_features = selector.get_support()
selected_feature_names = X.columns[selected_features]
print(selected_feature_names)

"""# **MENYIMPAN MODEL**"""

import joblib
joblib.dump(model, 'best_linear_regression_model.pkl')

from google.colab import files
files.download('best_linear_regression_model.pkl')

"""# **DASHBOARD**"""

!pip install pyngrok

!ngrok authtoken add-authtoken USE YOUR OWN AUTHTOKEN

!pip install streamlit

import streamlit as st

from pyngrok import ngrok
ngrok.kill()  # Matikan semua tunnel dan sesi ngrok aktif

from pyngrok import ngrok
import threading
import os

# Install ngrok jika belum terpasang
!pip install pyngrok

# Pasang authtoken ngrok (ganti dengan token milikmu)
!ngrok authtoken 2xLM3MjHsTByyLzPWWMNd7BjwrN_CHxtuR1F1Dn1wfKoch8r

from pyngrok import ngrok

# Membuat tunnel ke port 8501 (misalnya untuk streamlit)
public_url = ngrok.connect(8501)
print("Tunnel URL:", public_url)

def run_streamlit():
  os.system("streamlit run app.py --server.port 8501")
thread = threading.Thread(target=run_streamlit)
thread.start()

public_url = ngrok.connect(addr='8501')
print(public_url)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import numpy as np
# import joblib
# import plotly.express as px
# import plotly.graph_objects as go
# 
# 
# 
# st.set_page_config(
#     page_title="Dashboard Prediksi CO(GT) Berdasarkan Data Pendukung",
#     page_icon="üå´Ô∏è",
#     layout="wide"
# )
# 
# # Fungsi untuk memuat model
# @st.cache_resource
# def load_model():
#     return joblib.load('best_linear_regression_model.pkl')
# 
# # Load model
# model = load_model()
# 
# # Judul Dashboard
# st.title("Dashboard Prediksi Konsentrasi CO (GT)")
# 
# st.markdown("""
# ### Prediksi Konsentrasi Karbon Monoksida (CO - GT)
# Model Linear Regression ini memprediksi nilai CO (GT) berdasarkan 7 fitur:
# - NMHC(GT)
# - C6H6(GT)
# - NOx(GT)
# - NO2(GT)
# - RH (Kelembaban)
# - T (Temperatur)
# - AH (Absolute Humidity)
# """)
# 
# st.markdown("---")
# 
# # Input data pengguna
# st.subheader("Input Fitur untuk Prediksi")
# 
# col1, col2, col3 = st.columns(3)
# with col1:
#     nmhc = st.number_input("NMHC(GT)", value=85.0)
#     nox = st.number_input("NOx(GT)", value=60.0)
#     ah = st.number_input("AH", value=1.0)
# with col2:
#     c6h6 = st.number_input("C6H6(GT)", value=5.0)
#     no2 = st.number_input("NO2(GT)", value=30.0)
# with col3:
#     rh = st.number_input("RH", value=25.0)
#     t = st.number_input("T", value=10.0)
# 
# # Membuat DataFrame dari input
# input_df = pd.DataFrame([[nmhc, c6h6, nox, no2, rh, t, ah]],
#                         columns=['NMHC(GT)', 'C6H6(GT)', 'NOx(GT)', 'NO2(GT)', 'RH', 'T', 'AH'])
# st.write("Data input ke model:", input_df)
# prediction = model.predict(input_df)[0]
# st.success(f"Prediksi Konsentrasi CO (GT): {prediction:.2f}")
# 
# # Prediksi CO(GT)
# if st.button("Prediksi CO (GT)", type="primary"):
#     prediction = model.predict(input_df)[0]
# 
#     st.success(f"Prediksi Konsentrasi CO (GT): {prediction:.2f}")
# 
#     # Visualisasi
#     fig = go.Figure(data=[
#         go.Indicator(
#             mode="gauge+number",
#             value=prediction,
#             title={"text": "CO (GT)"},
#             gauge={
#                 "axis": {"range": [None, max(10, prediction + 1)]},
#                 "bar": {"color": "darkblue"},
#                 "steps": [
#                     {"range": [0, 2], "color": "lightgreen"},
#                     {"range": [2, 6], "color": "yellow"},
#                     {"range": [6, 10], "color": "orange"},
#                 ]
#             }
#         )
#     ])
#     fig.update_layout(height=400)
#     st.plotly_chart(fig)
# 
# st.markdown("---")
# st.caption("Dibuat untuk prediksi CO berbasis regresi linear.")
#

# Cari baris dengan nilai mendekati input
mask = (
    (dt['NMHC(GT)'].round(1) == 100.0) &
    (dt['C6H6(GT)'].round(1) == 5.0) &
    (dt['NOx(GT)'].round(1) == 50.0) &
    (dt['NO2(GT)'].round(1) == 30.0) &
    (dt['RH'].round(1) == 45.0) &
    (dt['T'].round(1) == 20.0) &
    (dt['AH'].round(2) == 0.9)
)

matched_rows = dt[mask]
if not matched_rows.empty:
    print("Baris cocok ditemukan:")
    print(matched_rows[['CO(GT)', 'NMHC(GT)', 'C6H6(GT)', 'NOx(GT)', 'NO2(GT)', 'RH', 'T', 'AH']])
else:
    print("Tidak ada baris yang cocok 100%, coba cari yang paling mirip.")

import numpy as np
x = np.array([[55.0, 10.0, 45.0, 37.0, 25.0, 15.0, 2.0]])
print(model.predict(x))